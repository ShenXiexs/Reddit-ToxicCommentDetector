{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c2be08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9997503161430359}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "result = classifier(\"I love how simple this API is!\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a5c7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "043ee3f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing BethesdaSoftworks_comments_deleted_extracted_after_toxic.csv: 100%|█| 5066/5066 [02:10<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved to /Users/samxie/Research/HEC/Reddit Sentiment 0417/Data_After/BethesdaSoftworks_comments_deleted_extracted_done.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Volkswagen_comments_deleted_extracted_after_toxic.csv: 100%|█| 24344/24344 [11:14<00:00, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved to /Users/samxie/Research/HEC/Reddit Sentiment 0417/Data_After/Volkswagen_comments_deleted_extracted_done.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gopro_comments_removed_extracted_after_toxic.csv: 100%|█| 2618/2618 [01:12<00:00, 36.16it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved to /Users/samxie/Research/HEC/Reddit Sentiment 0417/Data_After/gopro_comments_removed_extracted_done.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gopro_comments_deleted_extracted_after_toxic.csv: 100%|█| 18618/18618 [08:38<00:00, 35.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved to /Users/samxie/Research/HEC/Reddit Sentiment 0417/Data_After/gopro_comments_deleted_extracted_done.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing intel_comments_deleted_extracted_after_toxic.csv: 100%|█| 37156/37156 [18:28<00:00, 33.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved to /Users/samxie/Research/HEC/Reddit Sentiment 0417/Data_After/intel_comments_deleted_extracted_done.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ASUS_comments_removed_extracted_after_toxic.csv: 100%|█| 2128/2128 [00:59<00:00, 35.65it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved to /Users/samxie/Research/HEC/Reddit Sentiment 0417/Data_After/ASUS_comments_removed_extracted_done.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_folder = '/Users/samxie/Research/HEC/Reddit Sentiment 0417/Data_Before2'\n",
    "output_folder = '/Users/samxie/Research/HEC/Reddit Sentiment 0417/Data_After'\n",
    "\n",
    "\n",
    "MAX_SEQ_LEN = 512\n",
    "\n",
    "\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith('.csv'):\n",
    "        \n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        df = pd.read_csv(file_path, lineterminator='\\n')\n",
    "        \n",
    "        for i in tqdm(range(len(df)), desc=f\"Processing {file_name}\", ncols=100):\n",
    "            text = str(df.loc[i, 'body'])  \n",
    "            \n",
    "            if text.strip() == \"\":\n",
    "                continue\n",
    "            \n",
    "            encoding = tokenizer(text, truncation=True, padding=False, max_length=MAX_SEQ_LEN)\n",
    "            truncated_text = tokenizer.decode(encoding['input_ids'], skip_special_tokens=True)\n",
    "            \n",
    "            sentiment = classifier(truncated_text)[0]\n",
    "            df.loc[i, 'Sentiment_Label'] = 1 if sentiment['label'] == 'POSITIVE' else -1\n",
    "            df.loc[i, 'Sentiment_Score'] = round(sentiment['score'], 4)\n",
    "            df.loc[i, 'Sentiment_Score_Final'] = df.loc[i, 'Sentiment_Label'] * df.loc[i, 'Sentiment_Score']\n",
    "        \n",
    "        new_file_name = file_name.replace('_after_toxic', '')\n",
    "        new_file_name = new_file_name.replace('.csv', '_done.csv')\n",
    "        new_file_path = os.path.join(output_folder, new_file_name)\n",
    "        \n",
    "        df.to_csv(new_file_path, index=False)\n",
    "        \n",
    "        print(f\"Processed file saved to {new_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3133461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
