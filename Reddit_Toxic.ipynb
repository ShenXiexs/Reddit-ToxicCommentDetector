{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2fe8c3c",
   "metadata": {},
   "source": [
    "# Setting and Loading\n",
    "I downloaded Wiki Toxic comments from a Kaggle contest.\n",
    "I also followed two coding samples from Kaggle to write my own script. The links are: https://www.kaggle.com/code/nkaenzig/bert-tensorflow-2-huggingface-transformers \n",
    "and\n",
    "https://www.kaggle.com/code/kayrahanozcan/toxic-comment-classification-using-transformer-mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73eb78d",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Tokenization (Minimal for BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1609fadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re # Regular expressions for text cleaning (use cautiously with BERT)\n",
    "\n",
    "# Deep Learning Framework - Using PyTorch here\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Hugging Face Transformers\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, hamming_loss, accuracy_score # Accuracy is less informative for multi-label\n",
    "\n",
    "SEED = 202450412 # I set our discussing date as Seed\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED) # if using CUDA\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Configuration (Adjust these as needed)\n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "MAX_LENGTH = 128 # Max sequence length BERT can handle (adjust based on EDA)\n",
    "BATCH_SIZE = 8 # Adjust based on GPU memory\n",
    "EPOCHS = 3 # Number of training epochs (BERT fine-tuning usually requires few epochs)\n",
    "LEARNING_RATE = 2e-5 # Common learning rate for BERT fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65efd9d2",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "Preprocessing (Tokenization, Truncation & Padding); Creating efficient data pipelines using tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "511bb865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjust file paths as necessary\n",
    "try:\n",
    "    train_df = pd.read_csv('/Users/samxie/Research/HEC/Reddit Toxic 0412/Reddit Wiki Toxic/train.csv')\n",
    "    test_df = pd.read_csv('/Users/samxie/Research/HEC/Reddit Toxic 0412/Reddit Wiki Toxic/test.csv')\n",
    "    sample_submission_df = pd.read_csv('/Users/samxie/Research/HEC/Reddit Toxic 0412/Reddit Wiki Toxic/sample_submission.csv')\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Dataset files not found. Please check the input path.\")\n",
    "    # Dummy data for script structure execution if files are missing\n",
    "    train_df = pd.DataFrame({\n",
    "        'id': ['1','2','3','4','5'],\n",
    "        'comment_text': ['This is fine.', 'This is bad and obscene!', 'You are an idiot.', 'Explanation why the edits made under my username Hardcore Metallica Fan were reverted?', 'Go away!'],\n",
    "        'toxic': [0,1,1,0,0], 'severe_toxic': [0,0,0,0,0], 'obscene': [0,1,0,0,0],\n",
    "        'threat': [0,0,0,0,0], 'insult': [0,0,1,0,0], 'identity_hate': [0,0,0,0,0]\n",
    "    })\n",
    "    test_df = pd.DataFrame({\n",
    "        'id': ['10','11'],\n",
    "        'comment_text': ['Testing one two.', 'Another comment here.']\n",
    "    })\n",
    "    sample_submission_df = pd.DataFrame({\n",
    "        'id': ['10','11'], 'toxic': [0.5]*2, 'severe_toxic': [0.5]*2, 'obscene': [0.5]*2,\n",
    "        'threat': [0.5]*2, 'insult': [0.5]*2, 'identity_hate': [0.5]*2\n",
    "    })\n",
    "\n",
    "\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2cfb3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after downsampling: (30588, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>752b30fc7c411af8</td>\n",
       "      <td>Yes, my name is Scooter.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7e94591a809210ec</td>\n",
       "      <td>REDIRECT Talk:Bryan Wagner (American football)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7728121ab85b3e29</td>\n",
       "      <td>I shat somethin' out this mornin' prettier tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0451f492260efdcf</td>\n",
       "      <td>You did not ask for an answer. The article was...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46e5bacdf43bf51a</td>\n",
       "      <td>Archivesyou have a message re your last change...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  752b30fc7c411af8                           Yes, my name is Scooter.      0   \n",
       "1  7e94591a809210ec     REDIRECT Talk:Bryan Wagner (American football)      0   \n",
       "2  7728121ab85b3e29  I shat somethin' out this mornin' prettier tha...      1   \n",
       "3  0451f492260efdcf  You did not ask for an answer. The article was...      0   \n",
       "4  46e5bacdf43bf51a  Archivesyou have a message re your last change...      1   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       1              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        1       0       0              0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DownSampling - Balanced Dataset\n",
    "\n",
    "\n",
    "toxic_comments = train_df[train_df['toxic'] == 1]\n",
    "non_toxic_comments = train_df[train_df['toxic'] == 0]\n",
    "\n",
    "# I set Seed before: 20250412\n",
    "non_toxic_comments_sampled = non_toxic_comments.sample(n=len(toxic_comments), random_state=SEED)\n",
    "\n",
    "\n",
    "train_df = pd.concat([toxic_comments, non_toxic_comments_sampled])\n",
    "train_df = train_df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "print(f\"Size after downsampling: {train_df.shape}\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81bc3a2",
   "metadata": {},
   "source": [
    "***After downsampling, the size of dataset is 30,588, which is larger than 29,268 mentioned in paper!***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c85ab9f",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63557018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    # Remove URLs (optional, BERT might handle some context)\n",
    "    # text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Basic handling of common issues if needed\n",
    "    # text = text.lower() # BERT uncased models handle this\n",
    "    return text\n",
    "\n",
    "# Apply cleaning (demonstrative - may skip depending on BERT variant)\n",
    "# train_df['comment_text_cleaned'] = train_df['comment_text'].apply(clean_text)\n",
    "# test_df['comment_text_cleaned'] = test_df['comment_text'].apply(clean_text)\n",
    "# Use original text for now as BERT benefits from closer-to-raw text\n",
    "train_df['comment_text_cleaned'] = train_df['comment_text']\n",
    "test_df['comment_text_cleaned'] = test_df['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74be28c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Tokenization:\n",
      "Text: This is a sample comment for tokenization.\n",
      "Tokens: ['[CLS]', 'this', 'is', 'a', 'sample', 'comment', 'for', 'token', '##ization', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "Input IDs: tensor([[  101,  2023,  2003,  1037,  7099,  7615,  2005, 19204,  3989,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Example tokenization\n",
    "sample_text = \"This is a sample comment for tokenization.\"\n",
    "tokens = tokenizer.encode_plus(\n",
    "    sample_text,\n",
    "    max_length=32,\n",
    "    padding='max_length', # Pad to max_length\n",
    "    truncation=True,      # Truncate longer sequences\n",
    "    return_tensors='pt'   # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "print(\"\\nSample Tokenization:\")\n",
    "print(f\"Text: {sample_text}\")\n",
    "print(f\"Tokens: {tokenizer.convert_ids_to_tokens(tokens['input_ids'][0])}\")\n",
    "print(f\"Input IDs: {tokens['input_ids']}\")\n",
    "print(f\"Attention Mask: {tokens['attention_mask']}\") # 1 for real tokens, 0 for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "125a5d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train size: 27529, Validation size: 3059\n",
      "\n",
      "Sample batch shapes:\n",
      "Input IDs: torch.Size([16, 128])\n",
      "Attention Mask: torch.Size([16, 128])\n",
      "Labels: torch.Size([16, 6])\n"
     ]
    }
   ],
   "source": [
    "class ToxicCommentDataset(Dataset):\n",
    "    def __init__(self, comments, labels, tokenizer, max_len):\n",
    "        self.comments = comments\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comments)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        comment = str(self.comments[item])\n",
    "        target = self.labels[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            comment,\n",
    "            add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False, # Not needed for basic BERT classification\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt', # Return PyTorch tensors\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'comment_text': comment,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(target, dtype=torch.float) # Use float for BCEWithLogitsLoss\n",
    "        }\n",
    "\n",
    "# Prepare data for Dataset class\n",
    "X = train_df['comment_text_cleaned'].values\n",
    "y = train_df[label_cols].values\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.1, # Use 10% for validation\n",
    "    random_state=SEED,\n",
    "    # Stratification is complex for multi-label, can skip or use iterative stratification if needed\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain size: {len(X_train)}, Validation size: {len(X_val)}\")\n",
    "\n",
    "# Create Datasets\n",
    "train_dataset = ToxicCommentDataset(X_train, y_train, tokenizer, MAX_LENGTH)\n",
    "val_dataset = ToxicCommentDataset(X_val, y_val, tokenizer, MAX_LENGTH)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0) # number_workers depend on your system\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# Example batch check\n",
    "data = next(iter(train_dataloader))\n",
    "print(\"\\nSample batch shapes:\")\n",
    "print(\"Input IDs:\", data['input_ids'].shape)\n",
    "print(\"Attention Mask:\", data['attention_mask'].shape)\n",
    "print(\"Labels:\", data['labels'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd451377",
   "metadata": {},
   "source": [
    "## BERT Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbe1d9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, configuring it for multi-label\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(label_cols), # Number of output labels = number of toxic categories\n",
    "    output_attentions=False, # Optional: set to True if you want attention weights\n",
    "    output_hidden_states=False, # Optional: set to True if you want hidden states\n",
    ")\n",
    "\n",
    "# Move the model to the designated device (GPU or CPU)\n",
    "model.to(device)\n",
    "\n",
    "print(\"\\nModel loaded successfully.\")\n",
    "# print(model) # Uncomment to see model architecture details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14972dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=1e-8)\n",
    "\n",
    "# Total number of training steps\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0, # Optional: set a number of warmup steps (e.g., 0.1 * total_steps)\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Loss function for multi-label classification\n",
    "# BCEWithLogitsLoss combines a Sigmoid layer and Binary Cross Entropy loss in one class.\n",
    "# It's numerically more stable than using a plain Sigmoid followed by BCE Loss.\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d877de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = len(data_loader)\n",
    "\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        # Move batch to device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Clear previous gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        logits = outputs.logits # Raw model output (before sigmoid)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients to prevent exploding gradients (common practice)\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        scheduler.step() # Update learning rate\n",
    "\n",
    "        # Print progress (optional)\n",
    "        if (i + 1) % 100 == 0:\n",
    "             print(f'  Batch {i + 1}/{num_batches} | Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "    avg_train_loss = total_loss / num_batches\n",
    "    print(f\"\\n  Average Training Loss: {avg_train_loss:.4f}\")\n",
    "    return avg_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "554effdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Loop\n",
    "def eval_model(model, data_loader, loss_fn, device):\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    num_batches = len(data_loader)\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient calculation\n",
    "        for batch in data_loader:\n",
    "            # Move batch to device\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Store predictions (probabilities) and true labels\n",
    "            # Apply sigmoid to logits to get probabilities\n",
    "            probs = torch.sigmoid(logits)\n",
    "            all_preds.append(probs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = total_loss / num_batches\n",
    "    print(f\"  Average Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Concatenate results from all batches\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # Calculate metrics (example: ROC AUC per label, then average)\n",
    "    # Note: Handling potential errors if a label has only one class in the validation batch/set\n",
    "    roc_auc_scores = {}\n",
    "    mean_roc_auc = 0\n",
    "    try:\n",
    "        # Calculate AUC for each label individually\n",
    "        for i, label_name in enumerate(label_cols):\n",
    "             # Check if both classes are present for the current label\n",
    "             if len(np.unique(all_labels[:, i])) > 1:\n",
    "                 roc_auc_scores[label_name] = roc_auc_score(all_labels[:, i], all_preds[:, i])\n",
    "             else:\n",
    "                 roc_auc_scores[label_name] = np.nan # Or 0.5, or skip\n",
    "        # Calculate mean AUC, ignoring NaNs\n",
    "        mean_roc_auc = np.nanmean(list(roc_auc_scores.values()))\n",
    "        print(f\"  Mean ROC AUC: {mean_roc_auc:.4f}\")\n",
    "        print(\"  Individual ROC AUC Scores:\")\n",
    "        for name, score in roc_auc_scores.items():\n",
    "             print(f\"    {name}: {score:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Could not calculate ROC AUC: {e}\")\n",
    "\n",
    "\n",
    "    # Calculate Hamming Loss (fraction of wrongly predicted labels)\n",
    "    threshold = 0.5\n",
    "    binary_preds = (all_preds > threshold).astype(int)\n",
    "    hamming = hamming_loss(all_labels, binary_preds)\n",
    "    print(f\"  Hamming Loss: {hamming:.4f}\")\n",
    "\n",
    "    # (Optional) You can also calculate Micro/Macro F1 scores or Accuracy (less useful)\n",
    "    # print(\"\\nClassification Report (threshold=0.5):\")\n",
    "    # print(classification_report(all_labels, binary_preds, target_names=label_cols, zero_division=0))\n",
    "\n",
    "\n",
    "    return avg_val_loss, mean_roc_auc, hamming # Return key metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "664f4106",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training...\n",
      "\n",
      "--- Epoch 1/3 ---\n",
      "  Batch 100/3442 | Loss: 0.2278\n",
      "  Batch 200/3442 | Loss: 0.2434\n",
      "  Batch 300/3442 | Loss: 0.1180\n",
      "  Batch 400/3442 | Loss: 0.1020\n",
      "  Batch 500/3442 | Loss: 0.2051\n",
      "  Batch 600/3442 | Loss: 0.1249\n",
      "  Batch 700/3442 | Loss: 0.2565\n",
      "  Batch 800/3442 | Loss: 0.1874\n",
      "  Batch 900/3442 | Loss: 0.0925\n",
      "  Batch 1000/3442 | Loss: 0.2036\n",
      "  Batch 1100/3442 | Loss: 0.1363\n",
      "  Batch 1200/3442 | Loss: 0.3735\n",
      "  Batch 1300/3442 | Loss: 0.1213\n",
      "  Batch 1400/3442 | Loss: 0.1479\n",
      "  Batch 1500/3442 | Loss: 0.1607\n",
      "  Batch 1600/3442 | Loss: 0.0750\n",
      "  Batch 1700/3442 | Loss: 0.1651\n",
      "  Batch 1800/3442 | Loss: 0.0471\n",
      "  Batch 1900/3442 | Loss: 0.1113\n",
      "  Batch 2000/3442 | Loss: 0.0487\n",
      "  Batch 2100/3442 | Loss: 0.2096\n",
      "  Batch 2200/3442 | Loss: 0.1157\n",
      "  Batch 2300/3442 | Loss: 0.1295\n",
      "  Batch 2400/3442 | Loss: 0.1567\n",
      "  Batch 2500/3442 | Loss: 0.1402\n",
      "  Batch 2600/3442 | Loss: 0.1539\n",
      "  Batch 2700/3442 | Loss: 0.1516\n",
      "  Batch 2800/3442 | Loss: 0.1463\n",
      "  Batch 2900/3442 | Loss: 0.0707\n",
      "  Batch 3000/3442 | Loss: 0.1121\n",
      "  Batch 3100/3442 | Loss: 0.1730\n",
      "  Batch 3200/3442 | Loss: 0.1478\n",
      "  Batch 3300/3442 | Loss: 0.0701\n",
      "  Batch 3400/3442 | Loss: 0.1372\n",
      "\n",
      "  Average Training Loss: 0.1616\n",
      "\n",
      "--- Validation Epoch 1 ---\n",
      "  Average Validation Loss: 0.1382\n",
      "  Mean ROC AUC: 0.9671\n",
      "  Individual ROC AUC Scores:\n",
      "    toxic: 0.9835\n",
      "    severe_toxic: 0.9505\n",
      "    obscene: 0.9761\n",
      "    threat: 0.9710\n",
      "    insult: 0.9556\n",
      "    identity_hate: 0.9657\n",
      "  Hamming Loss: 0.0573\n",
      "  ** New best model saved with ROC AUC: 0.9671 **\n",
      "\n",
      "--- Epoch 2/3 ---\n",
      "  Batch 100/3442 | Loss: 0.1932\n",
      "  Batch 200/3442 | Loss: 0.3089\n",
      "  Batch 300/3442 | Loss: 0.0868\n",
      "  Batch 400/3442 | Loss: 0.1382\n",
      "  Batch 500/3442 | Loss: 0.0895\n",
      "  Batch 600/3442 | Loss: 0.1319\n",
      "  Batch 700/3442 | Loss: 0.0134\n",
      "  Batch 800/3442 | Loss: 0.0986\n",
      "  Batch 900/3442 | Loss: 0.2945\n",
      "  Batch 1000/3442 | Loss: 0.0678\n",
      "  Batch 1100/3442 | Loss: 0.2027\n",
      "  Batch 1200/3442 | Loss: 0.0735\n",
      "  Batch 1300/3442 | Loss: 0.0473\n",
      "  Batch 1400/3442 | Loss: 0.2999\n",
      "  Batch 1500/3442 | Loss: 0.1727\n",
      "  Batch 1600/3442 | Loss: 0.1131\n",
      "  Batch 1700/3442 | Loss: 0.1797\n",
      "  Batch 1800/3442 | Loss: 0.1968\n",
      "  Batch 1900/3442 | Loss: 0.0681\n",
      "  Batch 2000/3442 | Loss: 0.1784\n",
      "  Batch 2100/3442 | Loss: 0.1457\n",
      "  Batch 2200/3442 | Loss: 0.0883\n",
      "  Batch 2300/3442 | Loss: 0.0335\n",
      "  Batch 2400/3442 | Loss: 0.2712\n",
      "  Batch 2500/3442 | Loss: 0.0401\n",
      "  Batch 2600/3442 | Loss: 0.1191\n",
      "  Batch 2700/3442 | Loss: 0.0413\n",
      "  Batch 2800/3442 | Loss: 0.1443\n",
      "  Batch 2900/3442 | Loss: 0.0424\n",
      "  Batch 3000/3442 | Loss: 0.0790\n",
      "  Batch 3100/3442 | Loss: 0.0656\n",
      "  Batch 3200/3442 | Loss: 0.0729\n",
      "  Batch 3300/3442 | Loss: 0.0768\n",
      "  Batch 3400/3442 | Loss: 0.0879\n",
      "\n",
      "  Average Training Loss: 0.1140\n",
      "\n",
      "--- Validation Epoch 2 ---\n",
      "  Average Validation Loss: 0.1381\n",
      "  Mean ROC AUC: 0.9706\n",
      "  Individual ROC AUC Scores:\n",
      "    toxic: 0.9833\n",
      "    severe_toxic: 0.9525\n",
      "    obscene: 0.9772\n",
      "    threat: 0.9846\n",
      "    insult: 0.9562\n",
      "    identity_hate: 0.9697\n",
      "  Hamming Loss: 0.0564\n",
      "  ** New best model saved with ROC AUC: 0.9706 **\n",
      "\n",
      "--- Epoch 3/3 ---\n",
      "  Batch 100/3442 | Loss: 0.1546\n",
      "  Batch 200/3442 | Loss: 0.0560\n",
      "  Batch 300/3442 | Loss: 0.0803\n",
      "  Batch 400/3442 | Loss: 0.1350\n",
      "  Batch 500/3442 | Loss: 0.0545\n",
      "  Batch 600/3442 | Loss: 0.0980\n",
      "  Batch 700/3442 | Loss: 0.0553\n",
      "  Batch 800/3442 | Loss: 0.0297\n",
      "  Batch 900/3442 | Loss: 0.0432\n",
      "  Batch 1000/3442 | Loss: 0.0757\n",
      "  Batch 1100/3442 | Loss: 0.0445\n",
      "  Batch 1200/3442 | Loss: 0.0309\n",
      "  Batch 1300/3442 | Loss: 0.0339\n",
      "  Batch 1400/3442 | Loss: 0.0474\n",
      "  Batch 1500/3442 | Loss: 0.0299\n",
      "  Batch 1600/3442 | Loss: 0.0747\n",
      "  Batch 1700/3442 | Loss: 0.0189\n",
      "  Batch 1800/3442 | Loss: 0.0335\n",
      "  Batch 1900/3442 | Loss: 0.1123\n",
      "  Batch 2000/3442 | Loss: 0.1850\n",
      "  Batch 2100/3442 | Loss: 0.0668\n",
      "  Batch 2200/3442 | Loss: 0.0842\n",
      "  Batch 2300/3442 | Loss: 0.0354\n",
      "  Batch 2400/3442 | Loss: 0.1151\n",
      "  Batch 2500/3442 | Loss: 0.1979\n",
      "  Batch 2600/3442 | Loss: 0.2815\n",
      "  Batch 2700/3442 | Loss: 0.1758\n",
      "  Batch 2800/3442 | Loss: 0.1741\n",
      "  Batch 2900/3442 | Loss: 0.0432\n",
      "  Batch 3000/3442 | Loss: 0.0169\n",
      "  Batch 3100/3442 | Loss: 0.0539\n",
      "  Batch 3200/3442 | Loss: 0.0316\n",
      "  Batch 3300/3442 | Loss: 0.1420\n",
      "  Batch 3400/3442 | Loss: 0.1740\n",
      "\n",
      "  Average Training Loss: 0.0862\n",
      "\n",
      "--- Validation Epoch 3 ---\n",
      "  Average Validation Loss: 0.1485\n",
      "  Mean ROC AUC: 0.9701\n",
      "  Individual ROC AUC Scores:\n",
      "    toxic: 0.9820\n",
      "    severe_toxic: 0.9532\n",
      "    obscene: 0.9777\n",
      "    threat: 0.9833\n",
      "    insult: 0.9562\n",
      "    identity_hate: 0.9681\n",
      "  Hamming Loss: 0.0560\n",
      "\n",
      "Training Finished.\n",
      "Best Validation ROC AUC: 0.9706\n",
      "Loaded best model state for prediction.\n"
     ]
    }
   ],
   "source": [
    "# Execute Training and Evaluation\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_roc_auc': [], 'val_hamming': []}\n",
    "best_roc_auc = -1\n",
    "best_model_state = None\n",
    "\n",
    "print(\"\\nStarting Training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'\\n--- Epoch {epoch + 1}/{EPOCHS} ---')\n",
    "\n",
    "    train_loss = train_epoch(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler\n",
    "    )\n",
    "    history['train_loss'].append(train_loss)\n",
    "\n",
    "    print(f\"\\n--- Validation Epoch {epoch + 1} ---\")\n",
    "    val_loss, val_roc_auc, val_hamming = eval_model(\n",
    "        model,\n",
    "        val_dataloader,\n",
    "        loss_fn,\n",
    "        device\n",
    "    )\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_roc_auc'].append(val_roc_auc)\n",
    "    history['val_hamming'].append(val_hamming)\n",
    "\n",
    "    # Save the best model based on validation ROC AUC\n",
    "    if val_roc_auc > best_roc_auc:\n",
    "        best_roc_auc = val_roc_auc\n",
    "        best_model_state = model.state_dict()\n",
    "        torch.save(best_model_state, 'best_model_state.bin')\n",
    "        print(f\"  ** New best model saved with ROC AUC: {best_roc_auc:.4f} **\")\n",
    "\n",
    "print(\"\\nTraining Finished.\")\n",
    "print(f\"Best Validation ROC AUC: {best_roc_auc:.4f}\")\n",
    "\n",
    "# Load the best model state for prediction\n",
    "if best_model_state:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"Loaded best model state for prediction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327289d2",
   "metadata": {},
   "source": [
    "## BERT Model Prediction on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abc04f16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in test_texts: 153164\n",
      "Number of samples in test_dataset: 153164\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples in test_texts: {len(test_texts)}\")\n",
    "print(f\"Number of samples in test_dataset: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea8adb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in test_texts: 153164\n",
      "Number of samples in test_dataset: 153164\n",
      "Number of samples in test_dataloader: 19146\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class TestCommentDataset(Dataset):\n",
    "    def __init__(self, comments, tokenizer, max_len):\n",
    "        self.comments = comments\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comments)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        comment = str(self.comments[item])\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            comment,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        }\n",
    "\n",
    "test_texts = test_df['comment_text_cleaned'].values\n",
    "test_dataset = TestCommentDataset(test_texts, tokenizer, MAX_LENGTH)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Number of samples in test_texts: {len(test_texts)}\")\n",
    "print(f\"Number of samples in test_dataset: {len(test_dataset)}\")\n",
    "print(f\"Number of samples in test_dataloader: {len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "422c466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    print(\"\\nGenerating predictions on test data...\")\n",
    "\n",
    "    # progress bar\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Predicting\", unit=\"batch\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "            probs = torch.sigmoid(logits)  # Convert logits to probabilities (0-1 range)\n",
    "            predictions.append(probs.cpu().numpy())\n",
    "\n",
    "    return np.concatenate(predictions, axis=0)\n",
    "\n",
    "test_predictions = predict(model, test_dataloader, device)\n",
    "print(\"Predictions generated successfully.\")\n",
    "print(\"Shape of predictions:\", test_predictions.shape)  # Should be (num_test_samples, num_labels)\n",
    "\n",
    "\n",
    "test_predictions_df = pd.DataFrame(test_predictions, columns=label_cols)\n",
    "\n",
    "\n",
    "test_predictions_df['id'] = test_df['id'].values \n",
    "test_predictions_df = test_predictions_df[['id'] + label_cols]\n",
    "test_predictions_df.to_csv('test_prediction.csv', index=False)\n",
    "\n",
    "print(\"Prediction file 'test_prediction.csv' has been saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
